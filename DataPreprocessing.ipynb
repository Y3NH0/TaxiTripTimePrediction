{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8f05361",
   "metadata": {},
   "source": [
    "# Taxi_Task_Data_Preprocessing\n",
    "* input.\n",
    "    - train.csv\n",
    "    - test.csv\n",
    "* output.\n",
    "    - train_preprocessing.csv\n",
    "    - test_preprocessing.csv\n",
    "* description.\n",
    "    - we clean the data and generate some feature by raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e647a695-e14a-4433-8a4b-a531555cc721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import ast\n",
    "import time\n",
    "\n",
    "from joblib import load, dump\n",
    "\n",
    "import math\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45be83f6",
   "metadata": {},
   "source": [
    "# Read training/testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ffd4a23-3575-46d6-a8b1-d583ad1483df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1710670, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffa20d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19f3f68d",
   "metadata": {},
   "source": [
    "# Clean\n",
    "\n",
    "Clean the data with missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a1c6340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_missing_true(df):\n",
    "    return df[df.MISSING_DATA==False].reset_index(drop=True)\n",
    "def clean_empty_polyline(df):\n",
    "    return df[df.POLYLINE != '[]'].reset_index(drop=True)\n",
    "\n",
    "def TaxiData_Cleaning(df,mode='train'):\n",
    "    if mode == 'test':\n",
    "        print('Can not clean the testing data.')\n",
    "        return None\n",
    "    else:\n",
    "        tmp = df.shape\n",
    "        print('before first clean, shape:',tmp)\n",
    "        \n",
    "        df = clean_missing_true(df)\n",
    "        df = clean_empty_polyline(df)\n",
    "        \n",
    "        print('after cleaning')\n",
    "        print('\\tdelete',tmp[0]-df.shape[0],'records')\n",
    "        print('\\tnow, the shape of dataset:',df.shape)\n",
    "        return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cae4c6e1",
   "metadata": {},
   "source": [
    "# EDA: some categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdb9f7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    817881\n",
       "C    528019\n",
       "A    364770\n",
       "Name: CALL_TYPE, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.CALL_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "310b546d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0    80187\n",
       "57.0    50740\n",
       "9.0     34767\n",
       "33.0    34107\n",
       "23.0    33269\n",
       "        ...  \n",
       "41.0      506\n",
       "43.0      493\n",
       "8.0       378\n",
       "5.0        53\n",
       "48.0        7\n",
       "Name: ORIGIN_STAND, Length: 63, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.ORIGIN_STAND.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e52dbed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    1710670\n",
       "Name: DAY_TYPE, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.DAY_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95f69acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1710660\n",
       "True          10\n",
       "Name: MISSING_DATA, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.MISSING_DATA.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8db445e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000483    6704\n",
       "20000621    6549\n",
       "20000424    6459\n",
       "20000089    6421\n",
       "20000307    6272\n",
       "            ... \n",
       "20000312     491\n",
       "20000248     345\n",
       "20000585     270\n",
       "20000079      90\n",
       "20000170       7\n",
       "Name: TAXI_ID, Length: 439, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.TAXI_ID.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7bff064",
   "metadata": {},
   "source": [
    "# Preprocessing Func\n",
    "\n",
    "- timestamp 2 datatime\n",
    "- get start and end point from polyline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fd55c64",
   "metadata": {},
   "source": [
    "## timestamp 2 datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc2ff62c-8824-4775-9237-b44e883de6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp2dt(df):\n",
    "    '''\n",
    "    param. df:dataframe\n",
    "    return. df:dataframe\n",
    "    description.\n",
    "        df['timestamp'] -> df['year'],df['month'],df['day'],df['hour'],df['min'],df['weekday']\n",
    "        e.g.\n",
    "            1372636858 -> 2013, 7, 1, 0, 0, 0 (monday)\n",
    "        df['weekday']: 0 for Monday, 6 for Sunday\n",
    "\n",
    "    '''\n",
    "    df[\"TIMESTAMP\"] = [float(time) for time in df[\"TIMESTAMP\"]]\n",
    "    df[\"data_time\"] = [datetime.datetime.fromtimestamp(time, datetime.timezone.utc) for time in df[\"TIMESTAMP\"]]\n",
    "\n",
    "    df[\"year\"] = df[\"data_time\"].dt.year\n",
    "    df[\"month\"] = df[\"data_time\"].dt.month\n",
    "    df[\"day\"] = df[\"data_time\"].dt.day\n",
    "    df[\"hour\"] = df[\"data_time\"].dt.hour\n",
    "    df[\"min\"] = df[\"data_time\"].dt.minute\n",
    "    df[\"weekday\"] = df[\"data_time\"].dt.weekday # 0 for Monday, 6 for Sunday\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc62b6c1",
   "metadata": {},
   "source": [
    "## weekday group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32fae0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekday_group_gen(df):\n",
    "    '''\n",
    "    param. df:dataframe\n",
    "    return. df:dataframe\n",
    "    description.\n",
    "        Saturday, Sunday -> group 0 (peak)\n",
    "        Monday - Friday -> group 1 (off-peak)\n",
    "    '''\n",
    "    # key: cluster\n",
    "    weekday_mapping = { 0: 1, \n",
    "                        1: 1, \n",
    "                        2: 1, \n",
    "                        3: 1, \n",
    "                        4: 1, \n",
    "                        5: 0, \n",
    "                        6: 0 }\n",
    "    df['weekday_group'] = df['weekday'].apply(lambda x:weekday_mapping[x])\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13cb0616",
   "metadata": {},
   "source": [
    "## hour group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d337aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hr2group_dict_gen():\n",
    "#     df_tmp = pd.read_csv('train_preprocessing.csv')\n",
    "#     avg_period = dict()\n",
    "#     for i in range(24):\n",
    "#         avg_period[i] = (sum(df_tmp[df_tmp.hour == i].period)/len(df_tmp[df_tmp.hour == i]))\n",
    "\n",
    "#     hour2group = dict()\n",
    "#     curr_base = 612.553176503733\n",
    "#     curr_group_count = 0\n",
    "#     for k,v in dict(sorted(avg_period.items(), key=lambda item: item[1])).items():\n",
    "#         if(v<curr_base+50):\n",
    "#             hour2group[k] = curr_group_count\n",
    "#         else:\n",
    "#             curr_base = v\n",
    "#             curr_group_count += 1\n",
    "#             hour2group[k] = curr_group_count\n",
    "#     return hour2group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34316c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hour_group_gen(df):\n",
    "    hour2group = {  1: 0,\n",
    "                    0: 0,\n",
    "                    2: 0,\n",
    "                    23: 0,\n",
    "                    22: 0,\n",
    "                    21: 0,\n",
    "                    3: 0,\n",
    "                    4: 1,\n",
    "                    20: 1,\n",
    "                    5: 1,\n",
    "                    6: 1,\n",
    "                    19: 2,\n",
    "                    12: 2,\n",
    "                    13: 2,\n",
    "                    9: 2,\n",
    "                    11: 2,\n",
    "                    7: 2,\n",
    "                    10: 2,\n",
    "                    14: 3,\n",
    "                    8: 3,\n",
    "                    15: 3,\n",
    "                    18: 3,\n",
    "                    16: 4,\n",
    "                    17: 4  }\n",
    "    hour_group = list()\n",
    "    for i in df.index:\n",
    "        hour_group.append(hour2group[df.hour[i]])\n",
    "    df['hour_group'] = hour_group\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fb98089",
   "metadata": {},
   "source": [
    "## extract_start_end_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ebaa13-defc-420c-ac4e-97499a087313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_start_end_point(df,mode='train',test_EndPoint_source = 'y_test_end_point.csv'):\n",
    "    '''\n",
    "    param. df:dataframe\n",
    "    return. df:dataframe\n",
    "    description.\n",
    "        extract the start point, end point and period(travel time)\n",
    "        df['POLYLINE'] -> df['start_lon'], \n",
    "                          df['start_lat'], \n",
    "                          df['end_lon'],\n",
    "                          df['end_lat'],\n",
    "                          df['period']  (only train mode)\n",
    "        period = num of points in polyline * 15\n",
    "        \n",
    "    '''\n",
    "    if mode=='test':\n",
    "        start_lon_list = []\n",
    "        start_lat_list = []\n",
    "        for i in df.index:\n",
    "            try:\n",
    "                point_list = ast.literal_eval(df['POLYLINE'][i])\n",
    "                start_point = point_list[0]\n",
    "                start_lon_list.append(start_point[0])\n",
    "                start_lat_list.append(start_point[1])\n",
    "            except:\n",
    "                print('fail to extract start and end lon,lat: ',i)\n",
    "                start_lon_list.append(0)\n",
    "                start_lat_list.append(0)\n",
    "\n",
    "        df['start_lon'] = start_lon_list\n",
    "        df['start_lat'] = start_lat_list\n",
    "    \n",
    "        # read end point predicted by task1\n",
    "        if test_EndPoint_source == 'not_used_end_point':\n",
    "            print('not_used_end_point')\n",
    "            pass\n",
    "        elif test_EndPoint_source != None:\n",
    "            try:\n",
    "                df[['end_lon','end_lat']] = pd.read_csv(test_EndPoint_source)[['LONGITUDE','LATITUDE']]\n",
    "            except:\n",
    "                print('Fail to read TestingData.EndPoint source:',test_EndPoint_source)\n",
    "                print('Check the file:')\n",
    "                print('\\t1. exist?')\n",
    "                print('\\t2. Has the column name: [\\'LONGITUDE\\',\\'LATITUDE\\'] ?')\n",
    "\n",
    "    else:\n",
    "        start_lon_list = []\n",
    "        start_lat_list = []\n",
    "        mid_lon_list=[]\n",
    "        mid_lat_list=[]\n",
    "        end_lon_list = []\n",
    "        end_lat_list = []\n",
    "        period_list = []\n",
    "\n",
    "        for i in df.index:\n",
    "            try:\n",
    "                point_list = ast.literal_eval(df['POLYLINE'][i])\n",
    "                start_point = point_list[0]\n",
    "                start_lon_list.append(start_point[0])\n",
    "                start_lat_list.append(start_point[1])\n",
    "\n",
    "                mid_point = point_list[math.floor(len(point_list)/2)]\n",
    "                mid_lon_list.append(mid_point[0])\n",
    "                mid_lat_list.append(mid_point[1])\n",
    "\n",
    "                end_point = point_list[-1]\n",
    "                end_lon_list.append(end_point[0])\n",
    "                end_lat_list.append(end_point[1])\n",
    "\n",
    "                period_list.append( (len(point_list)-1) * 15 )\n",
    "            except:\n",
    "                print('fail to extract start and end lon,lat: ',i)\n",
    "                start_lon_list.append(0)\n",
    "                start_lat_list.append(0)\n",
    "                mid_lon_list.append(0)\n",
    "                mid_lat_list.append(0)\n",
    "                end_lon_list.append(0)\n",
    "                end_lat_list.append(0)\n",
    "                period_list.append(0)\n",
    "            \n",
    "        df['start_lon'] = start_lon_list\n",
    "        df['start_lat'] = start_lat_list\n",
    "        df['mid_lon'] = mid_lon_list\n",
    "        df['mid_lat'] = mid_lat_list\n",
    "        df['end_lon'] = end_lon_list\n",
    "        df['end_lat'] = end_lat_list\n",
    "        df['period'] = period_list\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbedaba7",
   "metadata": {},
   "source": [
    "## get distance between start, end and drop the row if its distance <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acb319c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lon_lat_distance(latA, lonA, latB, lonB):\n",
    "    '''\n",
    "    param. (lon,lat) of A point, B point\n",
    "    return. distance:float\n",
    "    description.\n",
    "        compute the distance between 2 points with the formula provided by kaggle competition\n",
    "    '''\n",
    "    lat = abs(latA-latB)*math.pi/180\n",
    "    lon = abs(lonA-lonB)*math.pi/180\n",
    "    latA = latA*math.pi/180\n",
    "    latB = latB*math.pi/180\n",
    "    a = math.sin(lat/2)*math.sin(lat/2)+math.cos(latA)*math.cos(latB)*math.sin(lon/2)*math.sin(lon/2)\n",
    "    distance = 2*math.atan2(math.sqrt(a),math.sqrt(1-a))\n",
    "    distance = 6371*distance\n",
    "\n",
    "    return distance\n",
    "\n",
    "def get_distance(df, mode='train',distance_threshold=1):\n",
    "    '''\n",
    "    param. df:dataframe\n",
    "    return. df:dataframe\n",
    "    description.\n",
    "        df['distance'] <- df['start_lat'], df['start_lon'], df['end_lat'], df['end_lon']\n",
    "    '''\n",
    "    try:\n",
    "        df['distance'] = [lon_lat_distance(df['start_lat'][i], df['start_lon'][i], df['end_lat'][i], df['end_lon'][i]) for i in df.index]\n",
    "    except:\n",
    "        print('fail to gen distance')\n",
    "    if mode=='train':\n",
    "        return clean_short_distance(df,threshold=distance_threshold)\n",
    "    return df\n",
    "\n",
    "def clean_short_distance(df,threshold=1):\n",
    "    '''\n",
    "    param. df:dataframe\n",
    "    return. df:dataframe\n",
    "    '''\n",
    "    return df[df.distance>threshold].reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fe3ee5c",
   "metadata": {},
   "source": [
    "## combine feature CALL_TYPE and ORIGIN_STAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79bb2973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_call_type_origin_stand(df):\n",
    "    '''\n",
    "    param. df:dataframe\n",
    "    return. df:dataframe\n",
    "    description.\n",
    "        df['CALL_TYPE_STAND'] <- df['CALL_TYPE'] + df['ORIGIN_STAND']\n",
    "        e.g. 'B7' <- 'B' + 7\n",
    "        \n",
    "        we try it since we suppose the feature 'CALL_TYPE' and 'ORIGIN_STAND' could imply some infomation about start point\n",
    "        e.g. start from specific station or hotspot\n",
    "    '''\n",
    "    df['CALL_TYPE_STAND'] =  list(map(lambda x:x if '0' in x else x[0], df['CALL_TYPE'] + df['ORIGIN_STAND'].astype(str)))\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cbdd6fbb",
   "metadata": {},
   "source": [
    "## Point Clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf6b4dd3",
   "metadata": {},
   "source": [
    "### point_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bed3b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_cluster(df,n_clusters=70,mode='train',test_end_cluster_method = 'KMEANS'):\n",
    "    '''\n",
    "    param. df:dataframe\n",
    "    return. df:dataframe\n",
    "    description.\n",
    "        df['StartCluster']  <- df['start_lon'], df['start_lat']\n",
    "        df['endCluster']  <- df['end_lon'], df['end_lat'] \n",
    "\n",
    "        points -> KMEANS -> every point belong to a cluster\n",
    "\n",
    "        in test mode: \n",
    "            StartCluster. \n",
    "                load the trained KMEANS model to predict a cluster for each start point\n",
    "            EndCluster.\n",
    "                1. test_end_cluster_method == 'KMEANS'\n",
    "                    load the trained KMEANS model to predict a cluster for each end point\n",
    "                2. test_end_cluster_method == 'RF'\n",
    "                    load the EndCluster predicted by RF model\n",
    "                    trace the code 'EndClusterModel.ipynb' if you wanna know the detail about this case\n",
    "    '''\n",
    "    if mode == 'test':\n",
    "        # test.StartCluster\n",
    "        model_filename = 'PointClusterModel' + str(n_clusters) + '.joblib'\n",
    "        cluster_model = load(model_filename)\n",
    "        df['StartCluster'] = cluster_model.predict(df[['start_lon','start_lat']].to_numpy())\n",
    "        \n",
    "        # 2 case for testing data generate the EndCluster\n",
    "        # case1. same as StartCluster\n",
    "        if test_end_cluster_method == 'KMEANS':\n",
    "            df['EndCluster'] = cluster_model.predict(df[['end_lon','end_lat']].to_numpy())\n",
    "        elif test_end_cluster_method == 'RF':\n",
    "        # case2. load EndCluster predicted by classifier\n",
    "            endcluster_source = pd.read_csv('TestEndCluster' + str(n_clusters) + '.csv')\n",
    "            df['EndCluster'] = endcluster_source['EndCluster']\n",
    "\n",
    "    elif mode == 'train':     \n",
    "        # init the model\n",
    "        cluster_model = KMeans(n_clusters=n_clusters,init='k-means++',random_state=87)\n",
    "\n",
    "        # set all the point (for training)\n",
    "        lon_tmp = list(df['end_lon'])\n",
    "        lon_tmp.extend(list(df['start_lon']))\n",
    "        lat_tmp = list(df['end_lat'])\n",
    "        lat_tmp.extend(list(df['start_lat']))\n",
    "        tmp = pd.DataFrame({'lon':lon_tmp,'lat':lat_tmp}).to_numpy()\n",
    "\n",
    "        # clustering\n",
    "        cluster_model.fit(tmp)\n",
    "\n",
    "        # convert start/end point to cluster\n",
    "        df['StartCluster'] = cluster_model.predict(df[['start_lon','start_lat']].to_numpy())\n",
    "        df['EndCluster'] = cluster_model.predict(df[['end_lon','end_lat']].to_numpy())\n",
    "        model_filename = 'PointClusterModel' + str(n_clusters) + '.joblib'\n",
    "        \n",
    "        # save the KMEANS model for testing\n",
    "        dump(cluster_model,model_filename)\n",
    "\n",
    "        # save the result of kmeans\n",
    "        tmp = pd.DataFrame({'lon':lon_tmp,'lat':lat_tmp})\n",
    "        tmp['Cluster'] = cluster_model.predict(tmp.to_numpy())\n",
    "        tmp.to_csv('ResultOfCluster.csv',index=False)\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3daa43fd",
   "metadata": {},
   "source": [
    "### generate_EndClusterTrainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6caabd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_EndClusterTrainData(k):\n",
    "    mode = 'train'\n",
    "    tmp = pd.read_csv('train.csv')\n",
    "    tmp = TaxiData_Cleaning(tmp, mode='train')\n",
    "    tmp = extract_start_end_point(tmp,mode=mode)\n",
    "    tmp = point_cluster(tmp,n_clusters=k,mode=mode)\n",
    "    tmp = timestamp2dt(tmp)\n",
    "    tmp = combine_call_type_origin_stand(tmp)\n",
    "    tmp[['CALL_TYPE_STAND','month','hour','weekday','StartCluster','EndCluster']]\\\n",
    "        .to_csv('EndClusterTrainData'+str(k)+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185ec9fd",
   "metadata": {},
   "source": [
    "## Summary of Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb9072bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TaxiData_Preprocessing(df,mode='train',distance_threshold=1,k_cluster=50,test_EndPoint_source = 'y_test_end_point.csv',test_end_cluster_method='KMEANS'):\n",
    "    df = timestamp2dt(df)\n",
    "    df = hour_group_gen(df)\n",
    "    df = extract_start_end_point(df,mode=mode,test_EndPoint_source=test_EndPoint_source)\n",
    "    df = get_distance(df,mode=mode,distance_threshold=distance_threshold)\n",
    "    df = combine_call_type_origin_stand(df)\n",
    "    df = point_cluster(df,n_clusters=k_cluster,mode=mode,test_end_cluster_method=test_end_cluster_method)\n",
    "    # feature_list = ['TAXI_ID','CALL_TYPE_STAND','CALL_TYPE','ORIGIN_STAND',\n",
    "    #                 'month','hour','weekday',\n",
    "    #                 'start_lon','start_lat','end_lon','end_lat',\n",
    "    #                 'StartCluster', 'EndCluster','distance']\n",
    "    # if mode == 'train':\n",
    "    #     feature_list.append('period')\n",
    "    # df = df[feature_list]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cb94ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveDataset(df,filename,feature_list = ['TAXI_ID','CALL_TYPE_STAND','CALL_TYPE','ORIGIN_STAND', 'month','hour','weekday', 'start_lon','start_lat','end_lon','end_lat', 'StartCluster', 'EndCluster','distance']):\n",
    "    df[feature_list].to_csv(filename,index=False)\n",
    "    print('Successfully Save ',filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d43e29a7",
   "metadata": {},
   "source": [
    "# Training Set Filter Method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26438661",
   "metadata": {},
   "source": [
    "## angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e921b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cal_Angle(df,remain_angle):\n",
    "    tmp = []\n",
    "    for i in df.index:\n",
    "        l1 = lon_lat_distance(df['start_lat'][i],df['start_lon'][i],df['end_lat'][i],df['end_lon'][i])\n",
    "        l2 = lon_lat_distance(df['start_lat'][i],df['start_lon'][i],df['mid_lat'][i],df['mid_lon'][i])\n",
    "        l3 = lon_lat_distance(df['mid_lat'][i],df['mid_lon'][i],df['end_lat'][i],df['end_lon'][i])\n",
    "        if l1*l2 != 0 :\n",
    "            try:\n",
    "                tmp_param = (l1**2+l2**2-l3**2)/(2*l1*l2)\n",
    "                tmp_param = round(tmp_param,3)\n",
    "                ans = math.degrees(math.acos(tmp_param))\n",
    "            except:\n",
    "                print((l1**2+l2**2-l3**2)/(2*l1*l2))\n",
    "        else:\n",
    "            ans = 1000\n",
    "        tmp.append(ans)\n",
    "    df['angle'] = tmp\n",
    "    df = df[df.angle<=remain_angle]\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1838899e",
   "metadata": {},
   "source": [
    "# Preprocess & Save"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4b563fa",
   "metadata": {},
   "source": [
    "## 1.a Task1 -> endpoint of testing data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49041b5c",
   "metadata": {},
   "source": [
    "### train_1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6de7089f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before first clean, shape: (1710670, 9)\n",
      "after cleaning\n",
      "\tdelete 5911 records\n",
      "\tnow, the shape of dataset: (1704759, 9)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "train_data = TaxiData_Cleaning(train_data, mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f2f84504",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TaxiData_Preprocessing(\n",
    "    train_data,\n",
    "    mode='train',\n",
    "    k_cluster=50,\n",
    "    distance_threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "93869261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.to_csv('train_preprocessing.csv',index=False)\n",
    "train_data.to_csv('train_1a.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1518e3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>POLYLINE</th>\n",
       "      <th>data_time</th>\n",
       "      <th>...</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>mid_lon</th>\n",
       "      <th>mid_lat</th>\n",
       "      <th>end_lon</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>period</th>\n",
       "      <th>distance</th>\n",
       "      <th>CALL_TYPE_STAND</th>\n",
       "      <th>StartCluster</th>\n",
       "      <th>EndCluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1372636858620000589</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000589</td>\n",
       "      <td>1.372637e+09</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.618643,41.141412],[-8.618499,41.141376],[...</td>\n",
       "      <td>2013-07-01 00:00:58+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>41.141412</td>\n",
       "      <td>-8.629110</td>\n",
       "      <td>41.151213</td>\n",
       "      <td>-8.630838</td>\n",
       "      <td>41.154489</td>\n",
       "      <td>330</td>\n",
       "      <td>1.776808</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1372637303620000596</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20000596</td>\n",
       "      <td>1.372637e+09</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.639847,41.159826],[-8.640351,41.159871],[...</td>\n",
       "      <td>2013-07-01 00:08:23+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>41.159826</td>\n",
       "      <td>-8.663112</td>\n",
       "      <td>41.163687</td>\n",
       "      <td>-8.665740</td>\n",
       "      <td>41.170671</td>\n",
       "      <td>270</td>\n",
       "      <td>2.480360</td>\n",
       "      <td>B7.0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1372636854620000520</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000520</td>\n",
       "      <td>1.372637e+09</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.574678,41.151951],[-8.574705,41.151942],[...</td>\n",
       "      <td>2013-07-01 00:00:54+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>41.151951</td>\n",
       "      <td>-8.588205</td>\n",
       "      <td>41.148963</td>\n",
       "      <td>-8.607996</td>\n",
       "      <td>41.142915</td>\n",
       "      <td>630</td>\n",
       "      <td>2.965199</td>\n",
       "      <td>C</td>\n",
       "      <td>17</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1372637091620000337</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000337</td>\n",
       "      <td>1.372637e+09</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.645994,41.18049],[-8.645949,41.180517],[-...</td>\n",
       "      <td>2013-07-01 00:04:51+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>41.180490</td>\n",
       "      <td>-8.671374</td>\n",
       "      <td>41.175180</td>\n",
       "      <td>-8.687268</td>\n",
       "      <td>41.178087</td>\n",
       "      <td>420</td>\n",
       "      <td>3.464589</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1372636965620000231</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000231</td>\n",
       "      <td>1.372637e+09</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.615502,41.140674],[-8.614854,41.140926],[...</td>\n",
       "      <td>2013-07-01 00:02:45+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>41.140674</td>\n",
       "      <td>-8.579133</td>\n",
       "      <td>41.144238</td>\n",
       "      <td>-8.578224</td>\n",
       "      <td>41.160717</td>\n",
       "      <td>375</td>\n",
       "      <td>3.835220</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458718</th>\n",
       "      <td>1404155105620000121</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20000121</td>\n",
       "      <td>1.404155e+09</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.606385,41.144742],[-8.606466,41.144742],[...</td>\n",
       "      <td>2014-06-30 19:05:05+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>41.144742</td>\n",
       "      <td>-8.593299</td>\n",
       "      <td>41.177214</td>\n",
       "      <td>-8.670150</td>\n",
       "      <td>41.236866</td>\n",
       "      <td>1050</td>\n",
       "      <td>11.550011</td>\n",
       "      <td>B9.0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458719</th>\n",
       "      <td>1404171463620000698</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000698</td>\n",
       "      <td>1.404171e+09</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.612469,41.14602],[-8.612487,41.145993],[-...</td>\n",
       "      <td>2014-06-30 23:37:43+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>41.146020</td>\n",
       "      <td>-8.611902</td>\n",
       "      <td>41.155749</td>\n",
       "      <td>-8.611344</td>\n",
       "      <td>41.171013</td>\n",
       "      <td>465</td>\n",
       "      <td>2.780690</td>\n",
       "      <td>C</td>\n",
       "      <td>28</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458720</th>\n",
       "      <td>1404171367620000670</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000670</td>\n",
       "      <td>1.404171e+09</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.610138,41.140845],[-8.610174,41.140935],[...</td>\n",
       "      <td>2014-06-30 23:36:07+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>41.140845</td>\n",
       "      <td>-8.613108</td>\n",
       "      <td>41.148234</td>\n",
       "      <td>-8.627454</td>\n",
       "      <td>41.158755</td>\n",
       "      <td>435</td>\n",
       "      <td>2.463359</td>\n",
       "      <td>C</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458721</th>\n",
       "      <td>1404141826620000248</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20000248</td>\n",
       "      <td>1.404142e+09</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.630712,41.154885],[-8.63073,41.154813],[-...</td>\n",
       "      <td>2014-06-30 15:23:46+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>41.154885</td>\n",
       "      <td>-8.614476</td>\n",
       "      <td>41.162184</td>\n",
       "      <td>-8.587026</td>\n",
       "      <td>41.173524</td>\n",
       "      <td>915</td>\n",
       "      <td>4.203449</td>\n",
       "      <td>B12.0</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458722</th>\n",
       "      <td>1404157147620000079</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>20000079</td>\n",
       "      <td>1.404157e+09</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.615538,41.140629],[-8.615421,41.140746],[...</td>\n",
       "      <td>2014-06-30 19:39:07+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>41.140629</td>\n",
       "      <td>-8.609535</td>\n",
       "      <td>41.146677</td>\n",
       "      <td>-8.620893</td>\n",
       "      <td>41.149881</td>\n",
       "      <td>390</td>\n",
       "      <td>1.122248</td>\n",
       "      <td>B34.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1458723 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID  \\\n",
       "0        1372636858620000589         C          NaN           NaN  20000589   \n",
       "1        1372637303620000596         B          NaN           7.0  20000596   \n",
       "2        1372636854620000520         C          NaN           NaN  20000520   \n",
       "3        1372637091620000337         C          NaN           NaN  20000337   \n",
       "4        1372636965620000231         C          NaN           NaN  20000231   \n",
       "...                      ...       ...          ...           ...       ...   \n",
       "1458718  1404155105620000121         B          NaN           9.0  20000121   \n",
       "1458719  1404171463620000698         C          NaN           NaN  20000698   \n",
       "1458720  1404171367620000670         C          NaN           NaN  20000670   \n",
       "1458721  1404141826620000248         B          NaN          12.0  20000248   \n",
       "1458722  1404157147620000079         B          NaN          34.0  20000079   \n",
       "\n",
       "            TIMESTAMP DAY_TYPE  MISSING_DATA  \\\n",
       "0        1.372637e+09        A         False   \n",
       "1        1.372637e+09        A         False   \n",
       "2        1.372637e+09        A         False   \n",
       "3        1.372637e+09        A         False   \n",
       "4        1.372637e+09        A         False   \n",
       "...               ...      ...           ...   \n",
       "1458718  1.404155e+09        A         False   \n",
       "1458719  1.404171e+09        A         False   \n",
       "1458720  1.404171e+09        A         False   \n",
       "1458721  1.404142e+09        A         False   \n",
       "1458722  1.404157e+09        A         False   \n",
       "\n",
       "                                                  POLYLINE  \\\n",
       "0        [[-8.618643,41.141412],[-8.618499,41.141376],[...   \n",
       "1        [[-8.639847,41.159826],[-8.640351,41.159871],[...   \n",
       "2        [[-8.574678,41.151951],[-8.574705,41.151942],[...   \n",
       "3        [[-8.645994,41.18049],[-8.645949,41.180517],[-...   \n",
       "4        [[-8.615502,41.140674],[-8.614854,41.140926],[...   \n",
       "...                                                    ...   \n",
       "1458718  [[-8.606385,41.144742],[-8.606466,41.144742],[...   \n",
       "1458719  [[-8.612469,41.14602],[-8.612487,41.145993],[-...   \n",
       "1458720  [[-8.610138,41.140845],[-8.610174,41.140935],[...   \n",
       "1458721  [[-8.630712,41.154885],[-8.63073,41.154813],[-...   \n",
       "1458722  [[-8.615538,41.140629],[-8.615421,41.140746],[...   \n",
       "\n",
       "                         data_time  ...  start_lat   mid_lon    mid_lat  \\\n",
       "0        2013-07-01 00:00:58+00:00  ...  41.141412 -8.629110  41.151213   \n",
       "1        2013-07-01 00:08:23+00:00  ...  41.159826 -8.663112  41.163687   \n",
       "2        2013-07-01 00:00:54+00:00  ...  41.151951 -8.588205  41.148963   \n",
       "3        2013-07-01 00:04:51+00:00  ...  41.180490 -8.671374  41.175180   \n",
       "4        2013-07-01 00:02:45+00:00  ...  41.140674 -8.579133  41.144238   \n",
       "...                            ...  ...        ...       ...        ...   \n",
       "1458718  2014-06-30 19:05:05+00:00  ...  41.144742 -8.593299  41.177214   \n",
       "1458719  2014-06-30 23:37:43+00:00  ...  41.146020 -8.611902  41.155749   \n",
       "1458720  2014-06-30 23:36:07+00:00  ...  41.140845 -8.613108  41.148234   \n",
       "1458721  2014-06-30 15:23:46+00:00  ...  41.154885 -8.614476  41.162184   \n",
       "1458722  2014-06-30 19:39:07+00:00  ...  41.140629 -8.609535  41.146677   \n",
       "\n",
       "          end_lon    end_lat  period   distance  CALL_TYPE_STAND  \\\n",
       "0       -8.630838  41.154489     330   1.776808                C   \n",
       "1       -8.665740  41.170671     270   2.480360             B7.0   \n",
       "2       -8.607996  41.142915     630   2.965199                C   \n",
       "3       -8.687268  41.178087     420   3.464589                C   \n",
       "4       -8.578224  41.160717     375   3.835220                C   \n",
       "...           ...        ...     ...        ...              ...   \n",
       "1458718 -8.670150  41.236866    1050  11.550011             B9.0   \n",
       "1458719 -8.611344  41.171013     465   2.780690                C   \n",
       "1458720 -8.627454  41.158755     435   2.463359                C   \n",
       "1458721 -8.587026  41.173524     915   4.203449            B12.0   \n",
       "1458722 -8.620893  41.149881     390   1.122248            B34.0   \n",
       "\n",
       "         StartCluster  EndCluster  \n",
       "0                   3          21  \n",
       "1                  27           1  \n",
       "2                  17          42  \n",
       "3                   1           9  \n",
       "4                   3          22  \n",
       "...               ...         ...  \n",
       "1458718            42           8  \n",
       "1458719            28          45  \n",
       "1458720            28          21  \n",
       "1458721            21          44  \n",
       "1458722             3           3  \n",
       "\n",
       "[1458723 rows x 28 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('train_1a.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78d243b9",
   "metadata": {},
   "source": [
    "### test_1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e9dd6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_data = TaxiData_Preprocessing(\n",
    "    df = test_data,\n",
    "    mode='test',\n",
    "    k_cluster=50,\n",
    "    distance_threshold=1,\n",
    "    test_EndPoint_source = 'y_test_end_point.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f2351c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('test_1a.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfc3711e",
   "metadata": {},
   "source": [
    "## 1.b RF clf -> EndCluster of testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "570e91b7",
   "metadata": {},
   "source": [
    "### train_1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f02c9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before first clean, shape: (1710670, 9)\n",
      "after cleaning\n",
      "\tdelete 5911 records\n",
      "\tnow, the shape of dataset: (1704759, 9)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "train_data = TaxiData_Cleaning(train_data, mode='train')\n",
    "train_data = TaxiData_Preprocessing(\n",
    "    train_data,\n",
    "    mode='train',\n",
    "    k_cluster=50,\n",
    "    distance_threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c9b974b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('train_1b.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf8c40be",
   "metadata": {},
   "source": [
    "### test_1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c5a158aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not_used_end_point\n",
      "fail to gen distance\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_data = TaxiData_Preprocessing(\n",
    "    df = test_data,\n",
    "    mode='test',\n",
    "    k_cluster=50,\n",
    "    distance_threshold=1,\n",
    "    test_EndPoint_source = 'not_used_end_point',\n",
    "    test_end_cluster_method='RF'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cf02996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('test_1b.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ceda6d97",
   "metadata": {},
   "source": [
    "## 2.a using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "948198e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_1a.csv')\n",
    "test_data = pd.read_csv('test_1a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1c1e1698",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = weekday_group_gen(train_data)\n",
    "test_data = weekday_group_gen(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7ab47b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('train_2a.csv',index=False)\n",
    "test_data.to_csv('test_2a.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1008398",
   "metadata": {},
   "source": [
    "## cluster: 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f17293d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before first clean, shape: (1710670, 9)\n",
      "after cleaning\n",
      "\tdelete 5911 records\n",
      "\tnow, the shape of dataset: (1704759, 9)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "train_data = TaxiData_Cleaning(train_data, mode='train')\n",
    "\n",
    "train_data = TaxiData_Preprocessing(\n",
    "    train_data,\n",
    "    mode='train',\n",
    "    k_cluster=2500,\n",
    "    distance_threshold=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c6a12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('train_cluster2500.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64284a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TRIP_ID', 'CALL_TYPE', 'ORIGIN_CALL', 'ORIGIN_STAND', 'TAXI_ID',\n",
       "       'TIMESTAMP', 'DAY_TYPE', 'MISSING_DATA', 'POLYLINE', 'data_time',\n",
       "       'year', 'month', 'day', 'hour', 'min', 'weekday', 'hour_group',\n",
       "       'start_lon', 'start_lat', 'mid_lon', 'mid_lat', 'end_lon', 'end_lat',\n",
       "       'period', 'distance', 'CALL_TYPE_STAND', 'StartCluster', 'EndCluster',\n",
       "       'weekday_group'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = weekday_group_gen(train_data)\n",
    "train_data = hour_group_gen(train_data)\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4f2e521",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[['TRIP_ID', 'CALL_TYPE', 'ORIGIN_CALL', 'ORIGIN_STAND', 'TAXI_ID','TIMESTAMP', 'DAY_TYPE',\n",
    "       'year', 'month', 'day', 'hour', 'min', 'weekday', 'hour_group',\n",
    "       'start_lon', 'start_lat', 'mid_lon', 'mid_lat', 'end_lon', 'end_lat',\n",
    "       'period', 'distance', 'CALL_TYPE_STAND', 'StartCluster', 'EndCluster',\n",
    "       'weekday_group']].to_csv('train_cluster2500.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e17d31d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_data = TaxiData_Preprocessing(\n",
    "    df = test_data,\n",
    "    mode='test',\n",
    "    k_cluster=2500,\n",
    "    distance_threshold=1,\n",
    "    test_EndPoint_source = 'y_test_end_point.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be701307",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('test_cluster2500.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f924df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = weekday_group_gen(test_data)\n",
    "test_data = hour_group_gen(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26dd2710",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[['TRIP_ID', 'CALL_TYPE', 'ORIGIN_CALL', 'ORIGIN_STAND', 'TAXI_ID','TIMESTAMP', 'DAY_TYPE',\n",
    "       'year', 'month', 'day', 'hour', 'min', 'weekday', 'hour_group',\n",
    "       'start_lon', 'start_lat', 'end_lon', 'end_lat'\n",
    "       , 'distance', 'CALL_TYPE_STAND', 'StartCluster', 'EndCluster',\n",
    "       'weekday_group']].to_csv('test_cluster2500.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55282d91",
   "metadata": {},
   "source": [
    "## angle filter -> training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07957458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before first clean, shape: (1710670, 9)\n",
      "after cleaning\n",
      "\tdelete 5911 records\n",
      "\tnow, the shape of dataset: (1704759, 9)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "train_data = TaxiData_Cleaning(train_data, mode='train')\n",
    "train_data = TaxiData_Preprocessing(train_data, mode='train')\n",
    "train_data = Cal_Angle(train_data,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d037571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Save  train_preprocessing_angle_filter.csv\n"
     ]
    }
   ],
   "source": [
    "SaveDataset(\n",
    "    df = train_data,\n",
    "    filename = 'train_preprocessing_angle_filter.csv',\n",
    "    feature_list = ['TAXI_ID','CALL_TYPE_STAND','CALL_TYPE','ORIGIN_STAND',\n",
    "                    'month','hour','weekday',\n",
    "                    'start_lon','start_lat','end_lon','end_lat',\n",
    "                    'StartCluster', 'EndCluster','distance','period']\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4188555",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4d59d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>POLYLINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000542</td>\n",
       "      <td>1408039037</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.585676,41.148522],[-8.585712,41.148639],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20000108</td>\n",
       "      <td>1408038611</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.610876,41.14557],[-8.610858,41.145579],[-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000370</td>\n",
       "      <td>1408038568</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.585739,41.148558],[-8.58573,41.148828],[-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>20000492</td>\n",
       "      <td>1408039090</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.613963,41.141169],[-8.614125,41.141124],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20000621</td>\n",
       "      <td>1408039177</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.619903,41.148036],[-8.619894,41.148036]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>T323</td>\n",
       "      <td>A</td>\n",
       "      <td>70885.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000430</td>\n",
       "      <td>1419171485</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.570196,41.159484],[-8.570187,41.158962],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>T324</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>20000020</td>\n",
       "      <td>1419170802</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.613873,41.141232],[-8.613882,41.141241],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>T325</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000207</td>\n",
       "      <td>1419172121</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.6481,41.152536],[-8.647461,41.15241],[-8....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>T326</td>\n",
       "      <td>A</td>\n",
       "      <td>76232.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000667</td>\n",
       "      <td>1419171980</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.571699,41.156073],[-8.570583,41.155929],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>T327</td>\n",
       "      <td>A</td>\n",
       "      <td>31208.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000255</td>\n",
       "      <td>1419171420</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.574561,41.180184],[-8.572248,41.17995],[-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID   TIMESTAMP  \\\n",
       "0        T1         B          NaN          15.0  20000542  1408039037   \n",
       "1        T2         B          NaN          57.0  20000108  1408038611   \n",
       "2        T3         B          NaN          15.0  20000370  1408038568   \n",
       "3        T4         B          NaN          53.0  20000492  1408039090   \n",
       "4        T5         B          NaN          18.0  20000621  1408039177   \n",
       "..      ...       ...          ...           ...       ...         ...   \n",
       "315    T323         A      70885.0           NaN  20000430  1419171485   \n",
       "316    T324         B          NaN          53.0  20000020  1419170802   \n",
       "317    T325         C          NaN           NaN  20000207  1419172121   \n",
       "318    T326         A      76232.0           NaN  20000667  1419171980   \n",
       "319    T327         A      31208.0           NaN  20000255  1419171420   \n",
       "\n",
       "    DAY_TYPE  MISSING_DATA                                           POLYLINE  \n",
       "0          A         False  [[-8.585676,41.148522],[-8.585712,41.148639],[...  \n",
       "1          A         False  [[-8.610876,41.14557],[-8.610858,41.145579],[-...  \n",
       "2          A         False  [[-8.585739,41.148558],[-8.58573,41.148828],[-...  \n",
       "3          A         False  [[-8.613963,41.141169],[-8.614125,41.141124],[...  \n",
       "4          A         False      [[-8.619903,41.148036],[-8.619894,41.148036]]  \n",
       "..       ...           ...                                                ...  \n",
       "315        A         False  [[-8.570196,41.159484],[-8.570187,41.158962],[...  \n",
       "316        A         False  [[-8.613873,41.141232],[-8.613882,41.141241],[...  \n",
       "317        A         False  [[-8.6481,41.152536],[-8.647461,41.15241],[-8....  \n",
       "318        A         False  [[-8.571699,41.156073],[-8.570583,41.155929],[...  \n",
       "319        A         False  [[-8.574561,41.180184],[-8.572248,41.17995],[-...  \n",
       "\n",
       "[320 rows x 9 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e154cde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TaxiData_Preprocessing(test_data,mode='test',k_cluster=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6318a82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Save  test_preprocessing_angle_filter.csv\n"
     ]
    }
   ],
   "source": [
    "SaveDataset(\n",
    "    df = test_data,\n",
    "    filename = 'test_preprocessing_angle_filter.csv',\n",
    "    feature_list = ['TAXI_ID','CALL_TYPE_STAND','CALL_TYPE','ORIGIN_STAND',\n",
    "                    'month','hour','weekday',\n",
    "                    'start_lon','start_lat','end_lon','end_lat',\n",
    "                    'StartCluster', 'EndCluster','distance']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f76107c",
   "metadata": {},
   "source": [
    "## Save current dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "785b0661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>POLYLINE</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>min</th>\n",
       "      <th>weekday</th>\n",
       "      <th>start_lon</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>end_lon</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>period</th>\n",
       "      <th>distance</th>\n",
       "      <th>CALL_TYPE_STAND</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1372636858620000589</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000589</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.618643,41.141412],[-8.618499,41.141376],[...</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.618643</td>\n",
       "      <td>41.141412</td>\n",
       "      <td>-8.630838</td>\n",
       "      <td>41.154489</td>\n",
       "      <td>330</td>\n",
       "      <td>1.776808</td>\n",
       "      <td>C</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1372637303620000596</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20000596</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.639847,41.159826],[-8.640351,41.159871],[...</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.639847</td>\n",
       "      <td>41.159826</td>\n",
       "      <td>-8.665740</td>\n",
       "      <td>41.170671</td>\n",
       "      <td>270</td>\n",
       "      <td>2.480360</td>\n",
       "      <td>B7.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1372636854620000520</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000520</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.574678,41.151951],[-8.574705,41.151942],[...</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.574678</td>\n",
       "      <td>41.151951</td>\n",
       "      <td>-8.607996</td>\n",
       "      <td>41.142915</td>\n",
       "      <td>630</td>\n",
       "      <td>2.965199</td>\n",
       "      <td>C</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1372637091620000337</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000337</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.645994,41.18049],[-8.645949,41.180517],[-...</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.645994</td>\n",
       "      <td>41.180490</td>\n",
       "      <td>-8.687268</td>\n",
       "      <td>41.178087</td>\n",
       "      <td>420</td>\n",
       "      <td>3.464589</td>\n",
       "      <td>C</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1372636965620000231</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000231</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.615502,41.140674],[-8.614854,41.140926],[...</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.615502</td>\n",
       "      <td>41.140674</td>\n",
       "      <td>-8.578224</td>\n",
       "      <td>41.160717</td>\n",
       "      <td>375</td>\n",
       "      <td>3.835220</td>\n",
       "      <td>C</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458718</th>\n",
       "      <td>1404155105620000121</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20000121</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.606385,41.144742],[-8.606466,41.144742],[...</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.606385</td>\n",
       "      <td>41.144742</td>\n",
       "      <td>-8.670150</td>\n",
       "      <td>41.236866</td>\n",
       "      <td>1050</td>\n",
       "      <td>11.550011</td>\n",
       "      <td>B9.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458719</th>\n",
       "      <td>1404171463620000698</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000698</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.612469,41.14602],[-8.612487,41.145993],[-...</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.612469</td>\n",
       "      <td>41.146020</td>\n",
       "      <td>-8.611344</td>\n",
       "      <td>41.171013</td>\n",
       "      <td>465</td>\n",
       "      <td>2.780690</td>\n",
       "      <td>C</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458720</th>\n",
       "      <td>1404171367620000670</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000670</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.610138,41.140845],[-8.610174,41.140935],[...</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.610138</td>\n",
       "      <td>41.140845</td>\n",
       "      <td>-8.627454</td>\n",
       "      <td>41.158755</td>\n",
       "      <td>435</td>\n",
       "      <td>2.463359</td>\n",
       "      <td>C</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458721</th>\n",
       "      <td>1404141826620000248</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20000248</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.630712,41.154885],[-8.63073,41.154813],[-...</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.630712</td>\n",
       "      <td>41.154885</td>\n",
       "      <td>-8.587026</td>\n",
       "      <td>41.173524</td>\n",
       "      <td>915</td>\n",
       "      <td>4.203449</td>\n",
       "      <td>B12.0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458722</th>\n",
       "      <td>1404157147620000079</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>20000079</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.615538,41.140629],[-8.615421,41.140746],[...</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.615538</td>\n",
       "      <td>41.140629</td>\n",
       "      <td>-8.620893</td>\n",
       "      <td>41.149881</td>\n",
       "      <td>390</td>\n",
       "      <td>1.122248</td>\n",
       "      <td>B34.0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1458723 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID  \\\n",
       "0        1372636858620000589         C          NaN           NaN  20000589   \n",
       "1        1372637303620000596         B          NaN           7.0  20000596   \n",
       "2        1372636854620000520         C          NaN           NaN  20000520   \n",
       "3        1372637091620000337         C          NaN           NaN  20000337   \n",
       "4        1372636965620000231         C          NaN           NaN  20000231   \n",
       "...                      ...       ...          ...           ...       ...   \n",
       "1458718  1404155105620000121         B          NaN           9.0  20000121   \n",
       "1458719  1404171463620000698         C          NaN           NaN  20000698   \n",
       "1458720  1404171367620000670         C          NaN           NaN  20000670   \n",
       "1458721  1404141826620000248         B          NaN          12.0  20000248   \n",
       "1458722  1404157147620000079         B          NaN          34.0  20000079   \n",
       "\n",
       "        DAY_TYPE  MISSING_DATA  \\\n",
       "0              A         False   \n",
       "1              A         False   \n",
       "2              A         False   \n",
       "3              A         False   \n",
       "4              A         False   \n",
       "...          ...           ...   \n",
       "1458718        A         False   \n",
       "1458719        A         False   \n",
       "1458720        A         False   \n",
       "1458721        A         False   \n",
       "1458722        A         False   \n",
       "\n",
       "                                                  POLYLINE  year  month  ...  \\\n",
       "0        [[-8.618643,41.141412],[-8.618499,41.141376],[...  2013      7  ...   \n",
       "1        [[-8.639847,41.159826],[-8.640351,41.159871],[...  2013      7  ...   \n",
       "2        [[-8.574678,41.151951],[-8.574705,41.151942],[...  2013      7  ...   \n",
       "3        [[-8.645994,41.18049],[-8.645949,41.180517],[-...  2013      7  ...   \n",
       "4        [[-8.615502,41.140674],[-8.614854,41.140926],[...  2013      7  ...   \n",
       "...                                                    ...   ...    ...  ...   \n",
       "1458718  [[-8.606385,41.144742],[-8.606466,41.144742],[...  2014      6  ...   \n",
       "1458719  [[-8.612469,41.14602],[-8.612487,41.145993],[-...  2014      6  ...   \n",
       "1458720  [[-8.610138,41.140845],[-8.610174,41.140935],[...  2014      6  ...   \n",
       "1458721  [[-8.630712,41.154885],[-8.63073,41.154813],[-...  2014      6  ...   \n",
       "1458722  [[-8.615538,41.140629],[-8.615421,41.140746],[...  2014      6  ...   \n",
       "\n",
       "         min  weekday  start_lon  start_lat   end_lon    end_lat  period  \\\n",
       "0          0        0  -8.618643  41.141412 -8.630838  41.154489     330   \n",
       "1          8        0  -8.639847  41.159826 -8.665740  41.170671     270   \n",
       "2          0        0  -8.574678  41.151951 -8.607996  41.142915     630   \n",
       "3          4        0  -8.645994  41.180490 -8.687268  41.178087     420   \n",
       "4          2        0  -8.615502  41.140674 -8.578224  41.160717     375   \n",
       "...      ...      ...        ...        ...       ...        ...     ...   \n",
       "1458718    5        0  -8.606385  41.144742 -8.670150  41.236866    1050   \n",
       "1458719   37        0  -8.612469  41.146020 -8.611344  41.171013     465   \n",
       "1458720   36        0  -8.610138  41.140845 -8.627454  41.158755     435   \n",
       "1458721   23        0  -8.630712  41.154885 -8.587026  41.173524     915   \n",
       "1458722   39        0  -8.615538  41.140629 -8.620893  41.149881     390   \n",
       "\n",
       "          distance  CALL_TYPE_STAND  Cluster  \n",
       "0         1.776808                C       52  \n",
       "1         2.480360             B7.0       23  \n",
       "2         2.965199                C       11  \n",
       "3         3.464589                C       15  \n",
       "4         3.835220                C       66  \n",
       "...            ...              ...      ...  \n",
       "1458718  11.550011             B9.0        5  \n",
       "1458719   2.780690                C       54  \n",
       "1458720   2.463359                C       52  \n",
       "1458721   4.203449            B12.0       63  \n",
       "1458722   1.122248            B34.0       27  \n",
       "\n",
       "[1458723 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d6094b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save the dataframe -> csv : train_data_1213.csv\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.fromtimestamp(time.time())\n",
    "now = str(now.month)+str(now.day)\n",
    "train_data.to_csv('train_data_' + now + '.csv' ,index=False)\n",
    "print('save the dataframe -> csv :','train_data_' + now + '.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yenho",
   "language": "python",
   "name": "yenho"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a04660ba35f143b12381d39bd59efae17d696f3bd8e2f5d3aa4628a6f72f105"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
